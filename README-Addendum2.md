# LLM Learning NOTES part 2
```cmd
venv\Scripts\activate
jupyter lab
```

### Week3 Day1
#### Learning Objectives
- Describe the 'HuggingFace' platform and everything it offers
- Look at Models, Datasets and Spaces
- Use Google CoLab to code on a high spec GPU runtime

#### HuggingFace Platform
The ubiquitous platform for LLM Engineers

- Models
    Over 800,000 Open Source Models of all shapes and sizes
        âœ… LLaMA 3 8B / 70B (by Meta)
        âœ… Mistral-7B (dense) and Mixtral 8x7B (MoE)
        âœ… Falcon 7B / 40B
        âœ… Whisper (by OpenAI) for speech-to-text transcription
        âœ… Coqui TTS, Bark, and XTTS 2 for text-to-speech synthesis        
        âœ… Stable Diffusion (by Stability AI) for image generation
        âœ… BGE & E5 Embedding Models for semantic search, RAG, and retrieval tasks
- Datasets
    A treasure trove of 200,000 datasets
- Spaces
    Apps, many built in Gradio, including Leaderboards
        - It's like an "App Store" for AI demos.
        - Each Space is a public web app built with tools like Gradio, Streamlit, or Static HTML.
        - You can interact with models immediately, without needing to write code or set up environments.

#### HuggingFace Libraries
And the astonishing leg up we get from them

- hub
    âœ… peft - Parameter-Efficient Fine-Tuning
- datasets
    âœ… trl - Reinforcement Learning from Human Feedback
    âœ… sfl - Supervised Fine-Tuning
- transformers
    âœ… accelerate - for distributed training and inference

#### HuggingFace 
https://huggingface.co/
https://huggingface.co/models
https://huggingface.co/datasets
https://huggingface.co/spaces

https://huggingface.co/spaces/jbilcke-hf/ai-comic-factory
https://huggingface.co/spaces/Kwai-Kolors/Kolors-Virtual-Try-On
https://huggingface.co/spaces/ed-donner/outsmart

##### HuggingFace Token
https://huggingface.co/settings/tokens

#### Code on a powerful GPU box 
Google Colab
- Run a Jupyter notebook in the cloud with a powerful runtime
- Collaborate with others
- Integrate with other Google services

Runtimes
1. CPU based
2. Lower spec GPU runtimes for lower cost
3. Higher spec GPU runtimes for resource intensive runs

https://colab.research.google.com/

https://colab.research.google.com/drive/18S8gmcFJZatl9BIIzWZaFYb3tgubUz2M#scrollTo=_oS1KxV8GKfl

```code
pipe = FluxPipeline.from_pretrained("black-forest-labs/FLUX.1-schnell",
    torch_dtype=torch.bfloat16).to("cuda")
generator = torch.Generator(device="cuda").manual_seed(0)
prompt = "A futuristic class full of students learning AI coding in the surreal style of Salvador Dali"

image = pipe(
    prompt,
    guidance_scale=0.0,
    num_inference_steps=4,
    max_sequence_length=256,
    generator=generator
).images[0]

image.save("surreal.png")
```

```note
# The above code is a simple example of how to use the HuggingFace library to generate an image using a pre-trained model.

ä½¿ç”¨ Hugging Face ä¸Šçš„ FluxPipeline æ–‡å­—è½‰åœ–åƒæ¨¡å‹ï¼Œé€é PyTorch åŠ CUDA GPU åŸ·è¡Œï¼Œç”¢ç”Ÿä¸€å¼µã€Œè¶…ç¾å¯¦é¢¨æ ¼ AI æ•™å®¤ã€çš„åœ–åƒï¼Œä¸¦å„²å­˜ç‚º surreal.pngã€‚
```

#### What you can now do
- Confidently code with Frontier Models
- Build a multi-modal AI Assistant with Tools
- Navigate the HuggingPlace platform; run code on Colab ***

### Week3 Day2
#### Learning Objectives
- Understand the 2 different levels of HuggingFace API
- Use pipelines for a wide variety of AI tasks
- Use pipelines to generate text, images and audio

#### The Two API Levels of Hugging Face
- Pipelines
    Higher level APIs to carry out standard tasks incredibly quickly (PoC)
- Tokenizers and Models
    Lower level APIs to provide the most power and control (Production)

#### Pipelines are incredibly versatile and simple
Unleash the power of open-source models in your solutions in 2 lines of code, å¸¸è¦‹ç”¨é€”ï¼ˆIcons + åŠŸèƒ½ï¼‰ï¼š
- ğŸ™‚ğŸ˜  Sentiment analysis
- ğŸ—‚ï¸ Classifier
- ğŸ§¾ğŸ§‘â€âš–ï¸ Named Entity Recognition
- â“ğŸ…°ï¸ Question Answering
- ğŸ“„ğŸ“„ğŸ“„ Summarizing
- ğŸ”ğŸŒ Translation
- ğŸ—£ï¸ Text to Speech
- ğŸ¤ Speech to Text

Use pipelines to generate content
- ğŸ“ Text
- ğŸ–¼ï¸ Image
- ğŸ™ï¸ Audio

Google Drive - Notebook (Week 3 day 2 - pipelines.ipynb)
https://colab.research.google.com/drive/1I3K2EzWC5MGyJlGEcmOMrTmHE4tVewbU#scrollTo=vgG4kcT_4lO_

#### What you can now do
- Confidently code with Frontier Models
- Build a multi-modal AI Assistant with Tools
- Use HuggingFace pipelines for a wide variety of inference tasks

### Week3 Day3
#### Learning Objectives
- Create tokenizers for models
- Translate between text and tokens
- Understand special tokens and chat templates

#### Introducing the Tokenizer
Maps between Text and Tokens for a particular model
- Translates between Text and Tokens with encode() and decode() methods '<|begin_of_text|>'
- Contains a Vocab that can include special tokens to signal information to the LLM, like start of prompt
- Can include a Chat Template that knows how to format a chat message for this model

| é …ç›®    | Tokenizer        | Embedding                     |
| ----- | ---------------- | ----------------------------- |
| åŠŸèƒ½    | å°‡æ–‡å­—è½‰æ›ç‚º token IDs | å°‡ token IDs è½‰æ›ç‚ºèªæ„å‘é‡           |
| è™•ç†å°è±¡  | æ–‡å­—ï¼ˆtextï¼‰         | token IDï¼ˆæ•´æ•¸ï¼‰                  |
| æ˜¯å¦å¯è¨“ç·´ | å¦ï¼ˆé€šå¸¸æ˜¯é è¨­è©å½™è¡¨ï¼‰      | æ˜¯ï¼ˆæ¨¡å‹è¨“ç·´æ™‚æ›´æ–°ï¼‰                    |
| ç¯„ä¾‹å·¥å…·  | `AutoTokenizer`  | Transformer æ¨¡å‹å…§éƒ¨çš„ embedding å±¤ |
| æ¨¡å‹ä¸­ä½ç½® | æ¨¡å‹å¤–éƒ¨ï¼ˆé è™•ç†ï¼‰        | æ¨¡å‹å…§éƒ¨ï¼ˆç¬¬ä¸€å±¤ï¼‰                     |
| è¼¸å…¥æ ¼å¼  | æ–‡å­—ï¼ˆstringï¼‰         | token IDï¼ˆæ•´æ•¸ï¼‰                  |
| è¼¸å‡ºæ ¼å¼  | token IDï¼ˆæ•´æ•¸ï¼‰         | èªæ„å‘é‡ï¼ˆå‘é‡ï¼‰                    |
| è½‰æ›æ–¹å¼  | å°‡æ–‡å­—è½‰æ›ç‚º token ID      | å°‡ token ID è½‰æ›ç‚ºèªæ„å‘é‡           |

#### The Tokenizers for key models
We will experiment with tokenizers for a variety of open-source models

- Llama 3.1 
    Meta led the way
- Phi 3
    Microsoft's entrant
- Qwen2
    Leader from Alibaba Cloud
- Starcoder2
    Coding model

```Note
1. Hugging Face Token with Write access
2. Hugging Face Models need to be authorized in advance via Web Site.
```

#### Pipeline Code
http://localhost:8888/lab/tree/week3/day2.pipelines.ipynb
https://colab.research.google.com/drive/1I3K2EzWC5MGyJlGEcmOMrTmHE4tVewbU  (T4 GPU)

#### Tokenizer Code
http://localhost:8888/lab/tree/week3/day3.tokenizers.ipynb
https://colab.research.google.com/drive/1Lvmx-_XVQ1ntldGWBY2NIfWlV-3pyvV0#scrollTo=y7LTUIlD9Gdm
