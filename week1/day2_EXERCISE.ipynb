{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI, also known as generative models or GANs (Generative Adversarial Networks), has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality content such as:\n",
      "\t* Product descriptions and product recommendations\n",
      "\t* Social media posts and ads\n",
      "\t* Blog articles and research papers\n",
      "\t* Music, videos, and other multimedia content\n",
      "2. **Image and Video Processing**:\n",
      "\t* Image editing and manipulation (e.g., removing noise, enhancing quality)\n",
      "\t* Object detection and classification\n",
      "\t* Facial recognition and analysis\n",
      "\t* Video compression and enhancement\n",
      "3. **Predictive Analytics**: Generative AI can generate forecasts and predictions based on historical data, enabling businesses to:\n",
      "\t* Predict sales trends and demand\n",
      "\t* Identify potential customers and segments\n",
      "\t* Optimize supply chain logistics\n",
      "4. **Chatbots and Conversational Interfaces**:\n",
      "\t* Personalized customer service chatbots\n",
      "\t* Intelligent virtual assistants (IVAs)\n",
      "\t* Customer support and feedback analysis\n",
      "5. **Marketing Automation**: Generative AI can help automate marketing processes such as:\n",
      "\t* Personalized email campaigns\n",
      "\t* Social media advertising optimization\n",
      "\t* Content recommendation engines\n",
      "6. **Data Analysis and Visualization**:\n",
      "\t* Data augmentation and feature engineering\n",
      "\t* Anomaly detection and outlier identification\n",
      "\t* Interactive data visualization tools\n",
      "7. **Customer Experience**: Generative AI can help create personalized customer experiences by:\n",
      "\t* Generating product recommendations based on user behavior\n",
      "\t* Predicting customer churn and identifying areas for improvement\n",
      "8. **Cybersecurity**: Generative AI can be used to:\n",
      "\t* Identify and predict potential security threats\n",
      "\t* Generate security protocols and signatures\n",
      "\t* Analyze and improve existing security systems\n",
      "9. **Supply Chain Optimization**:\n",
      "\t* Optimizing routes and logistics for delivery\n",
      "\t* Predicting demand and supply chain disruptions\n",
      "\t* Identifying bottlenecks and areas for improvement\n",
      "10. **Intellectual Property Protection**: Generative AI can help identify and protect intellectual property by:\n",
      "\t* Detecting plagiarism and unauthorized use of content\n",
      "\t* Generating unique and creative ideas\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as articles, social media posts, product descriptions, and more. This can be used to automate content creation, reduce costs, and increase efficiency.\n",
      "2. **Product Design**: Generative AI can design new products, packaging, and branding materials. This can help companies accelerate their product development process, reduce design costs, and create unique designs.\n",
      "3. **Marketing Automation**: Generative AI can generate personalized marketing messages, offers, and campaigns based on customer data and behavior. This can help companies improve their marketing efficiency and effectiveness.\n",
      "4. **Customer Service Chatbots**: Generative AI can power chatbots that provide 24/7 customer support, answering common questions, and helping customers with simple issues.\n",
      "5. **Content Moderation**: Generative AI can be used to moderate online content, detecting and removing hate speech, spam, or other forms of objectionable material.\n",
      "6. **Music and Audio Generation**: Generative AI can create new music tracks, sound effects, and audio samples for various industries such as film, gaming, and advertising.\n",
      "7. **Data Analysis and Visualization**: Generative AI can analyze large datasets and generate insights, visualizations, and reports to help businesses make data-driven decisions.\n",
      "8. **Image and Video Generation**: Generative AI can create realistic images and videos for various applications such as advertising, entertainment, and education.\n",
      "9. **Language Translation**: Generative AI can translate text and speech in real-time, enabling businesses to communicate with global customers more effectively.\n",
      "10. **Predictive Maintenance**: Generative AI can analyze sensor data from machines and predict potential failures, allowing companies to schedule maintenance and reduce downtime.\n",
      "11. **Financial Analysis and Risk Assessment**: Generative AI can analyze financial data and generate insights on market trends, predicting potential risks and opportunities for investors.\n",
      "12. **Human Resources**: Generative AI can be used to automate tasks such as employee onboarding, benefits administration, and performance evaluations.\n",
      "\n",
      "Some of the key industries that are already leveraging generative AI include:\n",
      "\n",
      "1. Advertising and Marketing\n",
      "2. Finance and Banking\n",
      "3. Healthcare and Pharmaceuticals\n",
      "4. Manufacturing and Supply Chain Management\n",
      "5. Entertainment and Media\n",
      "6. Education and Training\n",
      "7. Retail and E-commerce\n",
      "8. Logistics and Transportation\n",
      "\n",
      "As generative AI continues to evolve, we can expect to see even more innovative applications across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has a wide range of applications in various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as articles, social media posts, product descriptions, and more. This can help businesses streamline their content creation process and reduce the need for human writers.\n",
      "2. **Image and Video Generation**: Generative AI can be used to generate realistic images and videos that can be used in marketing materials, advertising, and other visual applications.\n",
      "3. **Automated Design**: Generative AI can be used to automate the design process for products such as logos, branding materials, and packaging.\n",
      "4. **Customer Service Chatbots**: Generative AI can be used to create chatbots that can understand customer inquiries and respond with relevant answers in real-time.\n",
      "5. **Personalized Recommendations**: Generative AI can be used to generate personalized product recommendations based on customer behavior and preferences.\n",
      "6. **Predictive Maintenance**: Generative AI can be used to predict equipment failures and recommend maintenance schedules to reduce downtime and improve overall efficiency.\n",
      "7. **Network Traffic Prediction**: Generative AI can be used to predict network traffic patterns and optimize internet connectivity to improve performance.\n",
      "8. **Speech Recognition**: Generative AI can be used to improve speech recognition accuracy in applications such as voice assistants, customer service chatbots, and transcription services.\n",
      "9. **Music Generation**: Generative AI can be used to generate new music compositions that can be used in various applications such as advertising, video game soundtracks, or film scores.\n",
      "10. **Product Development**: Generative AI can be used to simulate product designs and development processes, reducing the need for prototypes and improving overall efficiency.\n",
      "\n",
      "In terms of specific business applications, some examples include:\n",
      "\n",
      "* **E-commerce**: Using generative AI to generate high-quality product descriptions, images, and video content to enhance customer experience.\n",
      "* **Marketing**: Using generative AI to create personalized marketing messages, social media posts, and ad copy that resonates with specific target audiences.\n",
      "* **Healthcare**: Using generative AI to analyze medical data, predict patient outcomes, and develop personalized treatment plans.\n",
      "* **Finance**: Using generative AI to analyze financial data, identify patterns, and predict market trends.\n",
      "* **Education**: Using generative AI to create personalized learning materials, adaptive assessments, and intelligent tutoring systems.\n",
      "\n",
      "These are just a few examples of the many business applications that can be enabled by Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \u001b[K\n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out the definitions of some core concepts related to Large Language Models (LLMs). The key ones mentioned are neural networks, attention, and the transformer. Let me think through each one step by step.\n",
      "\n",
      "Starting with neural networks. From what I remember, neural networks are computational models inspired by the human brain's structure. They consist of many layers that process information. Each layer is a group of neurons connected to the previous one. These networks learn patterns from data and use their weights to make predictions or decisions. So in simple terms, neural networks are these structured systems where data flows through layers processing features until they reach the output.\n",
      "\n",
      "Now, attention. I think attention has two main aspects: local and global. Local attention refers to the idea that models focus on specific parts of input at a time, like how words in an analogy prompt attend to their individual parts. Global attention is about context by summarizing all information across different regions, important for tasks where understanding relationships between elements matters.\n",
      "\n",
      "Moving on to transformers. Transformers are neural network-based architectures with parallel layers in the forward and backward directions. Their structure allows each layer only to focus on its own features without interference from others during training. I think this self-attention mechanism is key here. It's a way of enabling models to weigh their previous computations, helping them understand context shifts by adjusting how they process sequences.\n",
      "\n",
      "Putting it all together, the fundamental units in an LLM are neural networks that perform structured feature processing with layers. Attention mechanisms come into play at local and global levels. Transformers leverage parallelism and self-attention through attention channels to handle sequential data effectively. All of this contributes to the models' ability to learn complex patterns in data.\n",
      "</think>\n",
      "\n",
      "The core concepts behind Large Language Models (LLMs) can be systematically defined as follows:\n",
      "\n",
      "1. **Neural Networks**: Neuronal network systems inspired by the human brain, designed to process and analyze information across layers for pattern recognition.\n",
      "\n",
      "2. **Attention (Local)**: The idea of focusing on specific input parts simultaneously, essential for understanding each word's role in analogy prompts.\n",
      "\n",
      "3. **Attention (Global)**: Summarizing relationships between different regions using global attention mechanisms to model interactions across the entire dataset.\n",
      "\n",
      "4. **Transformer**: A neural architecture with parallel layers, enabling focused processing of sequence data and self-attention for context awareness throughout training.\n",
      "\n",
      "5. **Attention Mechanism in Transformers**: Utilizes \"self-attention\" where models weigh their computations, enhancing their ability to adapt to varying contexts.\n",
      "\n",
      "These components collectively enable LLMs to process information through structured feature flow, use attention at local and global levels, and handle sequential data with parallel processing, all crucial for complex sequence modeling.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
